
hidden_layers: [64,64,64,96,96,128]
# num_pooling: 2
num_pooling: 1 # changed for pointmaze
acti: relu
use_layer_norm: False
output_dim: 64
type: cnn
