# SWEEPING OVER L1 PENALTY
# K=1
# python main.py algos='[acro]' n_epochs=14 algos.acro.l1_penalty=0.5    algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=1 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=14 algos.acro.l1_penalty=0.2    algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=1 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=14 algos.acro.l1_penalty=0.1    algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=1 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=14 algos.acro.l1_penalty=0.05   algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=1 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=14 algos.acro.l1_penalty=0.02   algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=1 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=14 algos.acro.l1_penalty=0.01   algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=1 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=14 algos.acro.l1_penalty=0.005  algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=1 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=14 algos.acro.l1_penalty=0.002  algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=1 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=14 algos.acro.l1_penalty=0.001  algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=1 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=14 algos.acro.l1_penalty=0.0005 algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=1 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=14 algos.acro.l1_penalty=0.0002 algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=1 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=14 algos.acro.l1_penalty=0.0001 algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=1 wandb=True train_evaluators=False

# K=2
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.5    algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=2 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.2    algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=2 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.1    algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=2 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.05   algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=2 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.02   algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=2 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.01   algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=2 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.005  algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=2 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.002  algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=2 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.001  algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=2 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.0005 algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=2 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.0002 algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=2 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.0001 algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=2 wandb=True train_evaluators=False

# K=3
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.5    algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=3 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.2    algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=3 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.1    algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=3 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.05   algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=3 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.02   algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=3 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.01   algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=3 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.005  algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=3 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.002  algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=3 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.001  algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=3 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.0005 algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=3 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.0002 algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=3 wandb=True train_evaluators=False
# python main.py algos='[acro]' n_epochs=80 algos.acro.l1_penalty=0.0001 algos.acro.dynamic_l1_penalty=False algos.acro.k_steps=3 wandb=True train_evaluators=False

# TESTING/SANDBOXING
python main.py algos='[acro]' n_epochs=14 algos.acro.k_steps=1 wandb=True train_evaluators=False name=acro_k1_no_eval_test
